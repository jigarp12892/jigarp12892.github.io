---
title: 'MeltpoolNet: Melt pool characteristic prediction in Metal Additive Manufacturing using machine learning: A summary'
date: 2022-07-19
permalink: /posts/2012/08/blog-post-2/
tags:
  - paper summary
  - 3dprinting
  - laser
  - additive manufacturing
  - machine learning
---


### Introduction:

This paper attempts to collect data from literature in order to build a training dataset that can predict melt pool shapes and melting regions in metal additive manufacturing (MAM)

In this process, a laser beam selectively melts regions of a bed of metal powder, and if the melting and subsequent cooling happens as desired, then it results in a fused metal component.

For those unfamiliar with L-PBF, here's is a 1 minute introduction:

[Quick intro to L-PBF](https://youtu.be/r8_M995cwAA?t=34)

Quick intro to L-PBF

As you can imagine, the point where the laser beam meets the powder bed is the critical region. That's where the melt-pool is created, which is highly transient and it's effective formation, movement and subsequent cooling defines the success of the final part. 

[Simulation of melt-pools in L-PBF](https://www.youtube.com/watch?v=IogJ0xujy_4)

Simulation of melt-pools in L-PBF

### The idea:

The idea behind this paper is simple but highly value adding. The authors built a training dataset from data-points found in literature across 4 different types of Metal AM processes, 29 different materials and a broad range of processing parameters. 

### Data collection:

The authors collecting 2200 instances from literature. Each instance had process parameters as features and melt pool length, width, depth, and defect type (Balling, lack of fusion, keyholing) as labels.

The dataset comprises of data collected from 4 different types of metal additive manufacturing (MAM) processes : Laser Powder Bed Fusion (L-PBF), Laser Directed Energy Deposition (L-DED), Electron Beam Powder Bed Fusion (EB-PBF), Electron Beam Directed Energy Deposition (EB-DED).

The machine learning models the authors use are trying to answer two questions:

**Classification:** What type of defect is it? Balling, lack of fusion or keyholing?

**Regression:** For a given set of parameters, what will be the value of melt-pool height, weight and depth?

### Data Preparation:

The authors used One hot encoding to convert all categorical features to numeric features. The authors used features that compromised of both process parameters and material properties. The material properties features considered included generated features such as alloy composition and Absorptivity coefficients. 

For the different machine learning tasks, the dataset sizes were as follows:

| Depth of meltpool | 1400 instances |
| --- | --- |
| Width of meltpool | 1200 instances |
| Length of meltpool | 320 instances |
| Meltpool classification | 1200 instances |

### The machine learning tasks:

The following models were used on the datasets:

1. Random Forest
2. Gaussian Process Model
3. Support Vector Machine
4. Ridge linear regression
5. Lasso linear regression
6. Gradient boosting trees
7. Logistic boosting trees
8. Logistic regression
9. Neural Network
10. XGBoost

- The best model for predicting melt pool depth was the neural network, which gave accuracy of 95.8% and Mean absolute error (MAE) of 20.54 $\mu$m.
- The best model for predicting melt pool depth was Gradient boosting in terms of accuracy (97.73%) and Neural Network in terms of MAE (6.92 $\mu$m).
- The best model for predicting melt pool length was Gradient boosting, with an accuracy of 99.62% and an MAE of 10.92 $\mu$m.
- Finally, for the classification tasks, the best accuracy (88.41%) and Area Under Curve - Receiver Operating Characteristics (0.98) was obtained by the use of the Random Forest model.

### Importance of dataset size

The authors also demonstrated the influence of dataset size on prediction performance, with performance metrics reported by running the various models on 20%, 40%, 60% 80% and 100% of the samples. Clearly, the an increase in the size of the training set, there was a marked decrease in the MAE values. The difference in MAE when using 20% of the samples vs using 100% of the samples was almost 29% in case of neural networks.

### Importance of features

The table below summarizes the top 5 most influential features for each prediction task, feature 1 being the most influential out of all features considered

| Prediction task | Feature 1 | Feature 2  | Feature 3 | Feature 4 | Feature 5 |
| --- | --- | --- | --- | --- | --- |
| Melt pool depth | Power | velocity | absorption coefficient | beam diameter  | hatch spacing |
| Melt pool width | layer thickness  | Power | absorption coefficient | velocity | beam diameter |
| Melt pool length | absorption coefficient | density | melting temperature | Power  | velocity |
| Defect classification | absorption coefficient | beam diameter | Power | velocity | melting temperature |

Note how the important features are more or less the same for each prediction task, but the order of importance keeps changing. It might point to why optimizing just 1 or 2 features is not always enough when trying to optimize metal AM processes. 

### Introducing interpretability:

The authors have also made an attempt at improving the interpretability of prediction tasks by coming up with an equation that is more ‘grey-box’ than machine learning tasks. 

**The identified model was obtained by considering a non-linear regression model using dimensional consistency as constraints.** The parameters and material properties considered while building this model were Power, velocity, density, specific heat, thermal conductivity and melting temperature. 

The $R^2$ value of the authors identified model is between the popular Rosenthal equation and the best $R^2$ values obtained by machine learning. See table below:

| Task | Rosenthal $R^2$ | Identified $R^2$ | ML $R^2$ |
| --- | --- | --- | --- |
| Depth | 0.654 | 0.787 | 0.958 |
| Width | 0.782 | 0.991 | 0.9773 |
| Length | -0.15 | 0.473 | 0.9962 |

### Conclusion:

The work done in this paper is an attempt to bridge some much needed gaps in interpretable machine learning in MAM as well as improving the training dataset quality and variety. The authors collected a fairly extensive dataset from literature and obtained robust accuracy with their machine learning tasks.

Moreover, the attempt to come up with an interpretable model using dimensional analysis and a manageable number of parameters also led to fair prediction accuracy.

Link to full paper: 

[MeltpoolNet: Melt pool characteristic prediction in Metal Additive Manufacturing using machine learning](https://www.sciencedirect.com/science/article/pii/S2214860422002172)